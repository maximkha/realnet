{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.0 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "c4a6cc1c2df5ddd62d6925b2a7bdee9abacf912eab37272999970e810b9642fd"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x161de2d03b0>"
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "torch.manual_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.Tensor([[0,0],[0,1], [1,0], [1,1]])\n",
    "Y = torch.Tensor([0,1,1,0]).view(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XOR(nn.Module):\n",
    "    def __init__(self, input_dim = 2, output_dim=1):\n",
    "        super(XOR, self).__init__()\n",
    "        self.lin1 = nn.Linear(input_dim, 2)\n",
    "        self.lin2 = nn.Linear(2, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.lin2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XOR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Linear):\n",
    "            # initialize the weight tensor, here we use a normal distribution\n",
    "            m.weight.data.normal_(0, 1)\n",
    "\n",
    "weights_init(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([-0.4615], grad_fn=<AddBackward0>)\n",
      "Epoch: 0, Loss: 0.21298818290233612, \n",
      "tensor([-1.1787], grad_fn=<AddBackward0>)\n",
      "Epoch: 500, Loss: 1.3893505334854126, \n",
      "tensor([-0.6011], grad_fn=<AddBackward0>)\n",
      "Epoch: 1000, Loss: 0.3612685799598694, \n",
      "tensor([-0.6452], grad_fn=<AddBackward0>)\n",
      "Epoch: 1500, Loss: 2.7065937519073486, \n",
      "tensor([0.1205], grad_fn=<AddBackward0>)\n",
      "Epoch: 2000, Loss: 0.014528144150972366, \n",
      "tensor([0.6545], grad_fn=<AddBackward0>)\n",
      "Epoch: 2500, Loss: 0.11934919655323029, \n",
      "tensor([0.4939], grad_fn=<AddBackward0>)\n",
      "Epoch: 3000, Loss: 0.24391748011112213, \n",
      "tensor([0.2651], grad_fn=<AddBackward0>)\n",
      "Epoch: 3500, Loss: 0.5401094555854797, \n",
      "tensor([0.3522], grad_fn=<AddBackward0>)\n",
      "Epoch: 4000, Loss: 0.12407005578279495, \n",
      "tensor([0.4432], grad_fn=<AddBackward0>)\n",
      "Epoch: 4500, Loss: 0.31007206439971924, \n",
      "tensor([0.2239], grad_fn=<AddBackward0>)\n",
      "Epoch: 5000, Loss: 0.05014360323548317, \n",
      "tensor([0.8054], grad_fn=<AddBackward0>)\n",
      "Epoch: 5500, Loss: 0.037881266325712204, \n",
      "tensor([0.8317], grad_fn=<AddBackward0>)\n",
      "Epoch: 6000, Loss: 0.028340572491288185, \n",
      "tensor([0.0490], grad_fn=<AddBackward0>)\n",
      "Epoch: 6500, Loss: 0.002398695796728134, \n",
      "tensor([0.0229], grad_fn=<AddBackward0>)\n",
      "Epoch: 7000, Loss: 0.0005232170224189758, \n",
      "tensor([0.9300], grad_fn=<AddBackward0>)\n",
      "Epoch: 7500, Loss: 0.004904464352875948, \n",
      "tensor([0.9157], grad_fn=<AddBackward0>)\n",
      "Epoch: 8000, Loss: 0.00709874089807272, \n",
      "tensor([0.9659], grad_fn=<AddBackward0>)\n",
      "Epoch: 8500, Loss: 0.0011625008191913366, \n",
      "tensor([0.9862], grad_fn=<AddBackward0>)\n",
      "Epoch: 9000, Loss: 0.00019075667660217732, \n",
      "tensor([0.9978], grad_fn=<AddBackward0>)\n",
      "Epoch: 9500, Loss: 4.9383506848244e-06, \n",
      "tensor([1.0000], grad_fn=<AddBackward0>)\n",
      "Epoch: 10000, Loss: 3.482014676592371e-11, \n"
     ]
    }
   ],
   "source": [
    "epochs = 10001\n",
    "steps = X.size(0)\n",
    "for i in range(epochs):\n",
    "    for j in range(steps):\n",
    "        data_point = np.random.randint(X.size(0))\n",
    "        x_var = Variable(X[data_point], requires_grad=False)\n",
    "        y_var = Variable(Y[data_point], requires_grad=False)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        y_hat = model(x_var)\n",
    "        loss = loss_func.forward(y_hat, y_var)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if i % 500 == 0:\n",
    "        print(y_hat)\n",
    "        print(\"Epoch: {0}, Loss: {1}, \".format(i, loss.data.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.7597, -0.4776],\n",
       "         [ 0.7230,  0.7230]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.4776, -0.7117], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-2.1265, -1.3831]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([1.0156], requires_grad=True)]"
      ]
     },
     "metadata": {},
     "execution_count": 85
    }
   ],
   "source": [
    "model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00],\n",
       "        [9.9999e-01],\n",
       "        [9.9999e-01],\n",
       "        [4.4107e-06]], grad_fn=<AddmmBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 86
    }
   ],
   "source": [
    "model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(2.1241675e-11, dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 87
    }
   ],
   "source": [
    "loss_func.forward(model(X), Y).data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.7343], grad_fn=<ReluBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 102
    }
   ],
   "source": [
    "F.relu(model.lin1(torch.Tensor([1,1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([-0.7598,  0.7343], grad_fn=<AddBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 103
    }
   ],
   "source": [
    "model.lin1(torch.Tensor([1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.7597, -0.4776],\n",
       "        [ 0.7230,  0.7230]], requires_grad=True)"
      ]
     },
     "metadata": {},
     "execution_count": 105
    }
   ],
   "source": [
    "model_params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([-0.7598,  0.7343], grad_fn=<AddBackward0>)"
      ]
     },
     "metadata": {},
     "execution_count": 110
    }
   ],
   "source": [
    "torch.matmul(torch.Tensor([1,1]), model_params[0].transpose(0, 1))+torch.Tensor([ 0.4776, -0.7117])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([-1.2374,  1.4460], grad_fn=<SqueezeBackward3>)"
      ]
     },
     "metadata": {},
     "execution_count": 112
    }
   ],
   "source": [
    "torch.matmul(torch.Tensor([1,1]), model_params[0].transpose(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([-1.2374,  1.4460], grad_fn=<SqueezeBackward3>)"
      ]
     },
     "metadata": {},
     "execution_count": 116
    }
   ],
   "source": [
    "torch.matmul(torch.Tensor([1,1]), model_params[0].transpose(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}